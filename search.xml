<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>RMSE(root mean square error) 均方根误差</title>
      <link href="/2023/06/28/rmse/"/>
      <url>/2023/06/28/rmse/</url>
      
        <content type="html"><![CDATA[<h2 id="MSE-mean-square-error-均方差"><a href="#MSE-mean-square-error-均方差" class="headerlink" title="MSE (mean square error) 均方差"></a>MSE (mean square error) 均方差</h2><p>真实值和预测值的方差求平均:</p><img src="/2023/06/28/rmse/RMSE-1.png" class=""><h2 id="RMSE-root-mean-square-error-均方根误差"><a href="#RMSE-root-mean-square-error-均方根误差" class="headerlink" title="RMSE (root mean square error) 均方根误差"></a>RMSE (root mean square error) 均方根误差</h2><p>MSE的平方根</p><img src="/2023/06/28/rmse/RMSE-2.png" class=""><p>RMSE 与标准差计算公式类似, 区别如下:<br>标准差是用来衡量一组数据自身的离散程度, 数据的每个元素与平均值的偏差.<br>RMSE 用来衡量预测值和真实值的偏差.</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN 卷积神经网络概述</title>
      <link href="/2023/06/18/cnn/"/>
      <url>/2023/06/18/cnn/</url>
      
        <content type="html"><![CDATA[<p>卷积神经网络（CNN）是一种深度学习的网络结构，在图像识别、自然语言处理、语音识别等领域取得了巨大的成功。其基本思想是通过卷积（Convolution）操作提取输入数据的特征，利用不同层次的卷积和池化操作来逐步提取和丰富特征，最终实现分类或识别任务。</p><h2 id="结构和原理"><a href="#结构和原理" class="headerlink" title="结构和原理"></a>结构和原理</h2><p>CNN的基本结构由输入层、卷积层（convolutional layer）、池化层（pooling layer，也称为取样层）、全连接层及输出层构成。卷积层和池化层一般会取若干个，采用卷积层和池化层交替设置，即一个卷积层连接一个池化层，池化层后再连接一个卷积层，依此类推。</p><p>输入层：输入层负责接收原始数据，可以是图像、文本、声音等不同类型的数据。对于图像处理任务，输入层通常是将图像像素的灰度或彩色值作为输入数据。</p><p>卷积层：卷积层是CNN的核心，通过卷积操作对输入数据进行特征提取。卷积操作使用一个可学习的滤波器（也称为卷积核）与输入数据进行逐点乘积累加，类似于一个滑动窗口，从而在输入数据中提取出有用的特征。这个卷积核是共享参数的，在整个网络的训练过程中，包含权值的卷积核也会随之更新，直到训练完成。 </p><p>池化层：池化层用于降低数据的维度，减少计算复杂度，同时保留重要特征，增强网络的泛化能力。池化操作可以是最大池化（Max Pooling）、平均池化（Average Pooling）等。</p><p>全连接层：全连接层通常用于神经网络的输出阶段，负责输出网络的预测结果。全连接层中的每个神经元都与前一层的所有神经元相连，根据对应的连接权值进行加权求和再加上偏置值，得到该神经元输入值。 </p><p>输出层：输出层负责输出网络的预测结果。对于分类任务，输出层通常采用Softmax函数将神经元的输出值转换为概率值，从而进行分类预测；对于回归任务，输出层可以采用线性回归模型或其他回归模型进行预测。</p><p>以上是卷积神经网络的基本结构，不同的任务和数据类型可能需要进一步调整和优化网络结构以及参数设置。在实际应用中，可以使用各种优化算法（如随机梯度下降、Adam等）对网络进行训练和调优，以获得更好的性能和准确率。</p><h2 id="卷积神经网络的特点"><a href="#卷积神经网络的特点" class="headerlink" title="卷积神经网络的特点"></a>卷积神经网络的特点</h2><p>卷积神经网络由多层感知机（MLP）演变而来，由于其具有局部区域连接、权值共享、降采样的结构特点，使得卷积神经网络在图像处理领域表现出色。卷积神经网络相比于其他神经网络的特殊性主要在于权值共享与局部连接两个方面。权值共享使得卷积神经网络的网络结构更加类似于生物神经网络。局部连接不像传统神经网络那样，第n-1层的每一神经元都与第n层的所有神经元连接，而是第n-1层的神经元与第n层的部分神经元之间连接。这两个特点的作用在于降低了网络模型的复杂度，减少了权值的数目。</p><ul><li><p>局部区域连接</p><p>  在传统的神经网络结构中，神经元之间的连接是全连接的，即n-1层的神经元与n层的所有神经元全部连接。但是在卷积神经网络中，n-1层与n 层的部分神经元连接。下图展示了全连接与局部连接的区别之处，左图为全连接示意图，由图可以看出前一层到后一层神经元之间都有边存在，每条边都有参数，由此可见全连接的参数很多。右边为局部连接，由图中可以看出仅存在少量的边，可见参数减少了很多。对比左右两图可以明显看出连接数成倍的减少，相应的参数也会减少。<br>      <img src="/2023/06/18/cnn/cnn_1.png" class=""></p></li><li><p>权值共享</p><ul><li><p>什么是权值共享呢？</p><p>  其实权值共享就是整张图片在使用同一个卷积核内的参数。比如一个3<em>3</em>1的卷积核，这个卷积核内9个的参数被整张图片共享，而不会因为图像内位置的不同而改变卷积核内的权系数。说的再通俗一点，就是用一个卷积核不改变其内权系数的情况下卷积处理整张图片。当然，CNN中每一个卷积层不会只有一个卷积核的，这样说只是为了方便解释。</p></li><li><p>权值共享的优点是什么呢？</p><p>  一是，权值共享的卷积操作保证了每一个像素都有一个权系数，只是这些系数被整个图片共享，因此大大减少了卷积核中参数量，降低了网络的复杂度。二是，传统的神经网络和机器学习方法需要对图像进行复杂的预处理提取特征，将得到特征再输入到神经网络中。而加入卷积操作就可以利用图片空间上的局部相关性，自动的提取特征。</p></li><li><p>那为什么卷积层会有多个卷积核呢？</p><p>  因为权值共享意味着每一个卷积核只能提取到一种特征，为了增加CNN的表达能力，需要设置多个卷积核。但是，每个卷积层中卷积核的个数是一个超参数。</p></li></ul></li><li><p>降采样</p><p>  降采样是卷积神经网络的另一重要概念，通常也称之为池化（Pooling）。最常见的方式有最大值（Max）池化、最小值（Min）池化、平均值（Average）池化。池化的好处是降低了图像的分辨率，整个网络也不容易过拟合。最大值池化如下图所示：</p>  <img src="/2023/06/18/cnn/cnn_2.png" class=""><p>  在图2是最大池化过程中，输入图像大小为4✖️4，在每2✖️2的区域中计算最大值。例如：</p>  <img src="/2023/06/18/cnn/cnn_3.png" class=""><p>  由于步长为2，因此每2✖️2的区域互不重叠，最后输出的池化特征大小为2✖️2，这个过程中分辨率变为原来的一半。</p></li></ul><h2 id="卷积神经网络的优缺点"><a href="#卷积神经网络的优缺点" class="headerlink" title="卷积神经网络的优缺点"></a>卷积神经网络的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>强大的特征学习能力：CNN能够自动从原始数据中学习和提取特征，这使得它在各种复杂任务中具有较高的性能。 </li><li>空间信息利用率高：CNN通过卷积操作能够充分利用输入数据的空间信息，从而在解决图像和自然语言处理问题时具有很好的效果。 </li><li>参数可学习性：CNN的参数可以通过反向传播算法进行学习和优化，这使得它能够对各种数据集进行有效的训练。</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>计算量大：CNN需要进行大量的卷积计算，这需要大量的计算资源和时间。</li><li>参数众多：与其它深度学习模型相比，CNN的参数数量较多，这使得模型的训练和调优过程变得更加复杂。</li></ul><h2 id="先进的CNN模型"><a href="#先进的CNN模型" class="headerlink" title="先进的CNN模型"></a>先进的CNN模型</h2><p>近年来，许多研究者提出了许多先进的卷积神经网络模型，以下是其中几个比较流行并且应用广泛的模型：</p><ul><li><p>ResNet（残差网络）：ResNet通过引入“残差块”有效地解决了深度神经网络中的梯度消失问题，使得网络可以设计得更深，性能更好。ResNet的主要特点是跨层连接，它通过引入捷径连接技术（shortcut connections）将输入跨层传递并与卷积的结果相加。在ResNet中只有一个池化层，它连接在最后一个卷积层后面。ResNet使得底层的网络能够得到充分训练，准确率也随着深度的加深而得到显著提升。将深度为152层的ResNet用于LSVRC-15的图像分类比赛中，它获得了第1名的成绩。ResNet在多个计算机视觉任务中取得了优异的成绩，包括图像分类、目标检测和语义分割等。</p></li><li><p>DenseNet（稠密网络）：DenseNet通过在网络中引入了稠密连接，使得信息可以直接从输入层传播到输出层。这种连接方式减少了梯度消失的问题，并能够更好地传播特征，从而使得网络更加高效。DenseNet在多个任务中均取得了优秀的性能。</p></li><li><p>EfficientNet：EfficientNet是一种既具有高精度又具有低计算复杂度的轻量级网络。它通过改变网络深度、宽度和分辨率的方式来提高网络的性能和效率。EfficientNet在图像分类任务中表现优异，且计算效率高，适用于移动设备和嵌入式系统。</p></li><li><p>MobileNet：MobileNet是为了移动设备和嵌入式设备设计的轻量级网络。它通过使用深度可分离的卷积（depthwise separable convolution）来减少参数量和计算复杂性，同时保持较高的性能。MobileNet广泛应用于移动应用、嵌入式设备和物联网设备中。</p></li><li><p>Transformer：尽管Transformer最初应用于自然语言处理任务，但近年来已广泛应用于计算机视觉任务。在CNN的基础上，Transformer引入了自注意力机制（self-attention mechanism），使得模型能够更好地捕捉输入数据的局部和全局信息。基于Transformer的模型在图像分类、目标检测和语义分割等任务中均取得了重大突破。</p></li><li><p>Inception V3：Inception V3 是 2015 年提出的一种 CNN 模型，它通过 Inception 模块将不同大小的卷积核和池化层结合起来，提高了模型的性能。Inception V3 在图像识别领域取得了巨大的成功。</p></li><li><p>YOLOv4：YOLOv4 是 2020 年提出的一种实时目标检测模型，它通过改进特征提取、目标回归和非极大值抑制等技术，提高了模型的性能。YOLOv4 在目标检测领域取得了巨大的成功。</p></li></ul><p>这些模型都在深度学习领域有着广泛的应用，并且在各种计算机视觉任务中持续取得优异的成绩。虽然这些模型有许多优点，但它们也需要根据具体的应用场景和数据进行适当的调整和优化。此外，这些模型的实现也需要相应的硬件和软件支持，以确保其计算效率和训练效果。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>本文对CNN结构及原理进行概念性的描述，并未进行深入学术研究。 主要列举了当前应用比较广泛的CNN改进模型，以便大家在具体应用中对模型的选择进行参考。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzU0NjgzMDIxMQ==&mid=2247571595&idx=3&sn=c04072ee69a028264b797e76d9a42957&chksm=fb543a67cc23b37165943ca27442b0ab267106a9664399d8d856756339b4d226205da194c476&scene=27">https://mp.weixin.qq.com/s?__biz=MzU0NjgzMDIxMQ==&amp;mid=2247571595&amp;idx=3&amp;sn=c04072ee69a028264b797e76d9a42957&amp;chksm=fb543a67cc23b37165943ca27442b0ab267106a9664399d8d856756339b4d226205da194c476&amp;scene=27</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Amazon codeWhisperer</title>
      <link href="/2023/06/14/amazon-codewhisperer/"/>
      <url>/2023/06/14/amazon-codewhisperer/</url>
      
        <content type="html"><![CDATA[<p>Amazon CodeWhisperer is a general purpose, machine learning-powered code generator that provides software developers with code recommendations in real time. As you write code, CodeWhisperer analyzes the English language comments and surrounding code to infer what code is needed to complete the task at hand. Your personalized recommendations can vary in size and scope, ranging from a single line comment to fully formed functions. </p><p>The code suggestions provided by CodeWhisperer are based on a large language models (LLMs) trained on billions of lines of code, including Amazon and open-source code. </p><h2 id="how-to-use"><a href="#how-to-use" class="headerlink" title="how to use"></a>how to use</h2><p>Getting started with CodeWhisperer is straightforward and documented <a href="https://aws.amazon.com/codewhisperer/resources/">here</a>. After setup, CodeWhisperer integrates with the IDE and provides code suggestions based on comments written in the IDE. Use TAB to accept a suggestion, ESC to reject the suggestion ALT+C (Windows)&#x2F;Option + C(MAC) to force a suggestion, and left and right arrow keys to switch between suggestions.</p><h2 id="Internal-use-wiki"><a href="#Internal-use-wiki" class="headerlink" title="Internal use wiki:"></a>Internal use wiki:</h2><p><a href="https://w.amazon.com/bin/view/Consolas/InternalUse">https://w.amazon.com/bin/view/Consolas/InternalUse</a></p><h2 id="CodeWhisperer-currently-supports"><a href="#CodeWhisperer-currently-supports" class="headerlink" title="CodeWhisperer currently supports:"></a>CodeWhisperer currently supports:</h2><p>C#, Java, JavaScript, Python, TypeScript, C, C++, SQL, Kotlin, Go, Scala, PHP, Ruby, Rust, Shell and SQL</p><h2 id="Is-CodeWhisperer-capable-of-writing-unit-tests-for-existing-code"><a href="#Is-CodeWhisperer-capable-of-writing-unit-tests-for-existing-code" class="headerlink" title="Is CodeWhisperer capable of writing unit tests for existing code?"></a>Is CodeWhisperer capable of writing unit tests for existing code?</h2><p>As of now, CodeWhisperer only takes current file into context, so if your function is another file, then the test won’t have relevant info.</p><h2 id="useful-skills"><a href="#useful-skills" class="headerlink" title="useful skills :"></a>useful skills :</h2><ol><li><p>Once CodeWhisperer is enabled, you will receive code suggestions in your code editor as you type. To manually trigger CodeWhisperer, use Option+C (MacOS) or Alt+C (Windows).</p></li><li><p>CodeWhisperer works most efficiently when developer comments are short and map to smaller discrete tasks so that no single function or code block is too long. Similarly, CodeWhisperer can generate helpful code suggestions when developers use intuitive names for various code elements, such as function names. The more code that is available as surrounding context, the better the suggestion will be.</p></li><li><p>If CodeWhisperer detects that its output matches particular open-source training data, the built-in reference tracker will notify you with a reference to the license type (for example, MIT or Apache) and a URL for the open-source project. You can then more easily find and review the referenced code and see how it is used in the context of another project before deciding whether to use it.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AIGC </tag>
            
            <tag> tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI和机器学习综述</title>
      <link href="/2023/06/13/ai-ml/"/>
      <url>/2023/06/13/ai-ml/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么学习-AI"><a href="#为什么学习-AI" class="headerlink" title="为什么学习 AI"></a>为什么学习 AI</h2><p>随着 ChatGPT 的爆火, AI已成为新一轮科技革命的主要驱动力, 将贯穿各个领域, 各个行业. 比如金融 教育 军事 生命科学等.各大科技公司都在开发自己的大模型, 各国之间也展开了激烈的竞争. 可谓得 AI 者得天下.</p><p>机器学习模型需要结合各个垂直领域的数据及专业知识来进行优化, 训练, 调参, 以解决各种复杂的专业问题.  作为一个开发人员, 我们不仅要知道各种机器学习模型适合解决的问题, 还要学习其背后的算法原理, 才能更好的应用到我们自己需要解决的问题中.</p><p>每个人都应该学习如何使用它们来提高工作效率, 解决实际问题. 不一定每个人都要掌握背后复杂的机器学习算法及原理, 就像互联网刚兴起的时候, 我们只需要学习怎么使用电脑和网络, 并不需要掌握 Http 网络协议或者计算机底层架构. </p><p><strong>很喜欢的一句话: 种一棵树最好的时间是十年前, 其次就是现在 !</strong></p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li>AGI: Artificial General Intelligence, “通用人工智能”，亦被称为强 AI，该术语指的是在任何你可以想象的人类的专业领域内，具备相当于人类智慧程度的 AI，一个 AGI 可以执行任何人类可以完成的任务。</li><li>AIGC: AI generated content，又称为生成式AI. AI从理解 识别内容，走向了自动生成内容，包括AIGC用于作画、图文、视频等多类型的内容创作.</li><li>LLM: Large Language Model, 大语言模型是指使用大量文本数据训练的深度学习模型，可以生成自然语言文本或理解语言文本的含义。</li><li>Transformer: 是Google Brain 2017的提出的，它针对RNN的弱点进行重新设计，解决了RNN效率问题和传递中的缺陷等，在很多问题上都超过了RNN的表现.</li><li>GPT: Generative Pre-trained Transformer，是一种基于Transformer模型的预训练语言模型.</li><li>BERT: Bidirectional Encoder Representations from Transformers, 通过在大规模的无标注语料上进行预训练学习，得到的模型可以应用于多个类型的下游任务，具体实现方式就是在具体下游任务的数据集上进行微调（fine-turn）学习。预训练的过程可以理解为我们学习基础知识，比如学习英语时的背单词，而微调就是具体的学习任务，比如完形填空，阅读理解等具体任务。</li><li>ML: Machine Learning, 是实现人工智能的一种最主要的技术</li><li>DL: Deep Learning, 是机器学习中的一个分支</li></ul><table><thead><tr><th>LLM</th><th>Comp.</th><th>参数量(十亿)</th><th>token量(万亿)</th><th>应用</th></tr></thead><tbody><tr><td>GPT</td><td>OpenAI</td><td>175B</td><td>-</td><td>ChatGPT</td></tr><tr><td>Palm2</td><td>Google</td><td>54B</td><td>3.6</td><td>Bard</td></tr><tr><td>LLaMA</td><td>Meta</td><td>-</td><td>1.4</td><td>Jarvis</td></tr></tbody></table><h2 id="机器学习的分类"><a href="#机器学习的分类" class="headerlink" title="机器学习的分类"></a>机器学习的分类</h2><img src="/2023/06/13/ai-ml/ml-01.png" class=""><ul><li><p>强化学习: 高阶的ML, 通过大量的action和reward 训练出policy使reward最大化</p></li><li><p>传统机器学习: 应用于早期比较简单数据量比较少的任务, 需要手动提取特征</p><ul><li>SVM 支持向量机</li><li>逻辑回归</li><li>线性回归</li><li>决策树</li><li>随机森林</li></ul></li><li><p>深度学习: 复杂数据量大的任务 CV, NLP, AR</p><ul><li>ANN: 人工神经网络 简称 NN (Neural Network) </li><li>RNN: 循环神经网络 Recurrent NN </li><li>CNN: 卷积神经网络 Convolutional NN</li><li>LSTM: 长短期记忆</li></ul></li></ul><h2 id="常用的机器学习库"><a href="#常用的机器学习库" class="headerlink" title="常用的机器学习库"></a>常用的机器学习库</h2><ul><li>TensorFlow: Google开源API 兼容Python 和 C, 前身是google神经网络算法库 “DistBelief”</li><li>PyTorch: 是一个开源的Python机器学习库，基于Torch，用于自然语言处理等应用程序。PyTorch既可以看作加入了GPU支持的numpy，同时也可以看成一个拥有自动求导功能的强大的深度神经网络.</li><li>scikit-learn(SKLearn) , 包含了除了深度学习和强化学习的几乎所有传统模型. Python的免费机器学习库. 具有各种分类,回归,聚类算法: 支持向量机 随机森林 梯度提升 … 它底层使用Scipy数据结构，与Python中其余使用Scipy、Numpy、Pandas和Matplotlib进行科学计算的部分适应地很好.</li><li>Keras：Python的人工神经网络开源库 支持后台转为TensorFlow &#x2F; Microsoft-CNTK &#x2F; Theano</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
